{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eron Fraud Identification\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Author :** Matheus Willian Machado  \n",
    "**Date :** Aug 10, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Project Overview\n",
    "---\n",
    "\n",
    ">Banque o detetive e coloque suas habilidades de aprendizado de máquina em uso através da construção de um algoritmo para identificar funcionários da Enron que possam ter cometido fraude. Sua base será um conjunto de dados financeiros e de e-mail público da Enron.\n",
    "> \n",
    "> (Udacity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "> Em 2000, Enron era uma das maiores empresas dos Estados Unidos. Já em 2002, ela colapsou e quebrou devido a uma fraude que envolveu grande parte da corporação. Resultando em uma investigação federal, muitos dados que são normalmente confidenciais, se tornaram públicos, incluindo dezenas de milhares de e-mails e detalhes financeiros para os executivos dos mais altos níveis da empresa. Neste projeto, você irá bancar o detetive, e colocar suas habilidades na construção de um modelo preditivo que visará determinar se um funcionário é ou não um funcionário de interesse (POI). Um funcionário de interesse é um funcionário que participou do escândalo da empresa Enron. Para te auxiliar neste trabalho de detetive, nós combinamos os dados financeiros e sobre e-mails dos funcionários investigados neste caso de fraude, o que significa que eles foram indiciados, fecharam acordos com o governo, ou testemunharam em troca de imunidade no processo.\n",
    "> \n",
    "> (Udacity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data, test_classifier, dump_classifier_and_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_project_dataset.pkl', 'rb') as f:\n",
    "    dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente o dataset disponibilizado, e serializado pela biblioteca _pickle_, foi carregado em uma variável. Udacity já havia informado que o arquivo tratava-se de uma combinação dos dados de e-mail e financeiros da base \"Eron email and financial\", estruturados em forma de dicionário. Onde cada chave representava o nome da pessoa e cada valor continha um outro dicionário, no qual estavam presentes os nomes dos atributos e seus respectivos valores para aquele indivíduo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>email_address</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>201955</td>\n",
       "      <td>2902</td>\n",
       "      <td>2869717</td>\n",
       "      <td>4484442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4175000</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>-126027</td>\n",
       "      <td>-3081055</td>\n",
       "      <td>1729541</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>1729541</td>\n",
       "      <td>2195</td>\n",
       "      <td>152</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>304805</td>\n",
       "      <td>1407</td>\n",
       "      <td>126027</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178980</td>\n",
       "      <td>182466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>477</td>\n",
       "      <td>566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>916197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>james.bannantine@enron.com</td>\n",
       "      <td>-560222</td>\n",
       "      <td>-5104</td>\n",
       "      <td>5243487</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>4046157</td>\n",
       "      <td>29</td>\n",
       "      <td>864523</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>465</td>\n",
       "      <td>1757552</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1295738</td>\n",
       "      <td>5634343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>10623258</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2660303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1586055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>239671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260455</td>\n",
       "      <td>827696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400000</td>\n",
       "      <td>frank.bay@enron.com</td>\n",
       "      <td>-82782</td>\n",
       "      <td>-201641</td>\n",
       "      <td>63014</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145796</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    salary to_messages deferral_payments total_payments  \\\n",
       "ALLEN PHILLIP K     201955        2902           2869717        4484442   \n",
       "BADUM JAMES P          NaN         NaN            178980         182466   \n",
       "BANNANTINE JAMES M     477         566               NaN         916197   \n",
       "BAXTER JOHN C       267102         NaN           1295738        5634343   \n",
       "BAY FRANKLIN R      239671         NaN            260455         827696   \n",
       "\n",
       "                   loan_advances    bonus               email_address  \\\n",
       "ALLEN PHILLIP K              NaN  4175000     phillip.allen@enron.com   \n",
       "BADUM JAMES P                NaN      NaN                         NaN   \n",
       "BANNANTINE JAMES M           NaN      NaN  james.bannantine@enron.com   \n",
       "BAXTER JOHN C                NaN  1200000                         NaN   \n",
       "BAY FRANKLIN R               NaN   400000         frank.bay@enron.com   \n",
       "\n",
       "                   restricted_stock_deferred deferred_income  \\\n",
       "ALLEN PHILLIP K                      -126027        -3081055   \n",
       "BADUM JAMES P                            NaN             NaN   \n",
       "BANNANTINE JAMES M                   -560222           -5104   \n",
       "BAXTER JOHN C                            NaN        -1386055   \n",
       "BAY FRANKLIN R                        -82782         -201641   \n",
       "\n",
       "                   total_stock_value      ...      from_poi_to_this_person  \\\n",
       "ALLEN PHILLIP K              1729541      ...                           47   \n",
       "BADUM JAMES P                 257817      ...                          NaN   \n",
       "BANNANTINE JAMES M           5243487      ...                           39   \n",
       "BAXTER JOHN C               10623258      ...                          NaN   \n",
       "BAY FRANKLIN R                 63014      ...                          NaN   \n",
       "\n",
       "                   exercised_stock_options from_messages    other  \\\n",
       "ALLEN PHILLIP K                    1729541          2195      152   \n",
       "BADUM JAMES P                       257817           NaN      NaN   \n",
       "BANNANTINE JAMES M                 4046157            29   864523   \n",
       "BAXTER JOHN C                      6680544           NaN  2660303   \n",
       "BAY FRANKLIN R                         NaN           NaN       69   \n",
       "\n",
       "                   from_this_person_to_poi    poi  long_term_incentive  \\\n",
       "ALLEN PHILLIP K                         65  False               304805   \n",
       "BADUM JAMES P                          NaN  False                  NaN   \n",
       "BANNANTINE JAMES M                       0  False                  NaN   \n",
       "BAXTER JOHN C                          NaN  False              1586055   \n",
       "BAY FRANKLIN R                         NaN  False                  NaN   \n",
       "\n",
       "                   shared_receipt_with_poi restricted_stock director_fees  \n",
       "ALLEN PHILLIP K                       1407           126027           NaN  \n",
       "BADUM JAMES P                          NaN              NaN           NaN  \n",
       "BANNANTINE JAMES M                     465          1757552           NaN  \n",
       "BAXTER JOHN C                          NaN          3942714           NaN  \n",
       "BAY FRANKLIN R                         NaN           145796           NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame.from_dict(dic, orient='index')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando a biblioteca pandas foi possível transformar o dicionário em um _data frame_ (estrutura tabelada e semelhante a uma matrix). Nele, cada atributo representava uma coluna, cada indivíduo uma linha, e seus nomes foram utilizados como índices.\n",
    "As 5 primeiras linhas da estrutura foram apresentadas e, com base nelas, notou-se uma grande quantidade de valores \"NaN\", ou seja, sem informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "salary                       95 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "email_address                111 non-null object\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "other                        93 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "poi                          146 non-null bool\n",
      "long_term_incentive          66 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "dtypes: bool(1), float64(19), object(1)\n",
      "memory usage: 24.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.replace('NaN', np.nan, inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores de texto \"NaN\" foram substituidos pela representação da biblioteca Numpy, facilitando assim sua contagem. Além disso, utilizou-se a função \"info\" a fim de obter não somente uma visão da quantidade de informações faltantes, como também do tipo de dado de cada atributo, além das dimensões do _dataframe_ (número de linhas e colunas).\n",
    "É importante ressaltar que a grande maioria dos atributos são do tipo _float_, a exceção de \"email_address\" e \"poi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    128\n",
       "True      18\n",
       "Name: poi, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'poi'\n",
    "data[label].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o campo \"poi\", do tipo booleano, foi realizada uma contagem dos representantes de cada classes (\"True\" e \"False\"). O processo revelou um grande desbalanceamento entre elas, já que a grande maioria dos dados estão concentrados na classe \"False\" enquanto que um pouco mais de 10% encontravam-se na outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['email_address'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['email_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto ao campo \"email_address\", do tipo objeto, foi realizado uma contagem de valores únicos, para dimensionar a quantidade de classes presentes no mesmo. Como resultado, haviam tantas quanto células preenchidas (111 itens), o que representaria um atributo candidato a índice. No entanto, sabendo que os nomes dos indivíduos já estavam realizando essa função, optou-se remover aquele campo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary                        1\n",
       "to_messages                   4\n",
       "deferral_payments            13\n",
       "total_payments                0\n",
       "loan_advances                17\n",
       "bonus                         2\n",
       "restricted_stock_deferred    18\n",
       "deferred_income               7\n",
       "total_stock_value             0\n",
       "expenses                      0\n",
       "from_poi_to_this_person       4\n",
       "exercised_stock_options       6\n",
       "from_messages                 4\n",
       "other                         0\n",
       "from_this_person_to_poi       4\n",
       "poi                           0\n",
       "long_term_incentive           6\n",
       "shared_receipt_with_poi       4\n",
       "restricted_stock              1\n",
       "director_fees                18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = data[data[label] == 1].isnull().sum()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deferral_payments',\n",
       " 'loan_advances',\n",
       " 'restricted_stock_deferred',\n",
       " 'deferred_income',\n",
       " 'director_fees']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = data[label].value_counts()[1]/3\n",
    "few_poi_values = s[s > limit].index.tolist()\n",
    "few_poi_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devido a preocupação com o grande desbalanceamento entre os rótulos, somados à noção da quantidade da células não preenchidas, foi estudado a parcela de valores faltante, em todos os campos, para os registros pertencentes à classe \"True\" (pessoas de interesse). Visando evitar que a falta de informação fosse reconhecida como sendo uma caracteristica desse grupo, foram listados os campos que continha menos de 2/3 de completude, para remoção futura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOCKHART EUGENE E</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   salary  to_messages  deferral_payments  total_payments  \\\n",
       "LOCKHART EUGENE E     NaN          NaN                NaN             NaN   \n",
       "\n",
       "                   loan_advances  bonus  restricted_stock_deferred  \\\n",
       "LOCKHART EUGENE E            NaN    NaN                        NaN   \n",
       "\n",
       "                   deferred_income  total_stock_value  expenses  \\\n",
       "LOCKHART EUGENE E              NaN                NaN       NaN   \n",
       "\n",
       "                   from_poi_to_this_person  exercised_stock_options  \\\n",
       "LOCKHART EUGENE E                      NaN                      NaN   \n",
       "\n",
       "                   from_messages  other  from_this_person_to_poi    poi  \\\n",
       "LOCKHART EUGENE E            NaN    NaN                      NaN  False   \n",
       "\n",
       "                   long_term_incentive  shared_receipt_with_poi  \\\n",
       "LOCKHART EUGENE E                  NaN                      NaN   \n",
       "\n",
       "                   restricted_stock  director_fees  \n",
       "LOCKHART EUGENE E               NaN            NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.drop(label, axis=1).isnull().all(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linhas que continham apenas valores nulos também foram procuradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = ['salary',\n",
    "            'deferral_payments',\n",
    "            'loan_advances',\n",
    "            'bonus',\n",
    "            'deferred_income',\n",
    "            'expenses',\n",
    "            'long_term_incentive',\n",
    "            'other',\n",
    "            'director_fees',\n",
    "            'total_payments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[payments] = data[payments].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fim de verificar a validade da coluna \"total_payments\" separou-se os atributos de pagamento para soma dos valores e batimento dos resultados. Por se tratar de dados financeiros, optou-se por preencher os dados sem informação com valor 0, tal como está no pdf disponibilizado como insumo, permitindo assim a realização das operações elencadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>expenses</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>102500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>15456290.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  salary  deferral_payments  loan_advances  bonus  \\\n",
       "BELFER ROBERT        0.0          -102500.0            0.0    0.0   \n",
       "BHATNAGAR SANJAY     0.0                0.0            0.0    0.0   \n",
       "\n",
       "                  deferred_income  expenses  long_term_incentive     other  \\\n",
       "BELFER ROBERT                 0.0       0.0                  0.0       0.0   \n",
       "BHATNAGAR SANJAY              0.0       0.0                  0.0  137864.0   \n",
       "\n",
       "                  director_fees  total_payments  \n",
       "BELFER ROBERT            3285.0        102500.0  \n",
       "BHATNAGAR SANJAY       137864.0      15456290.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[payments[:-1]].sum(axis=1) != data.total_payments][payments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = ['deferred_income','deferral_payments', 'expenses', 'director_fees', 'total_payments']\n",
    "data.loc['BELFER ROBERT',correct] = np.array([-102500, 0, 3285, 102500, 3285])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = ['other', 'expenses', 'director_fees', 'total_payments']\n",
    "data.loc['BHATNAGAR SANJAY',correct] = np.array([0, 137864, 0, 137864])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante a validação, dois registros apresentaram valores discrepantes: \"BELFER ROBERT\" e \"BHATNAGAR SANJAY\". O pdf foi utilizado para consultar os dados corretos e logo após foi realizado o recadastramento manual dos mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = ['restricted_stock_deferred',\n",
    "         'restricted_stock',\n",
    "         'exercised_stock_options',\n",
    "         'total_stock_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[stock] = data[stock].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>44093.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>-44093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>15456290.0</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  restricted_stock_deferred  restricted_stock  \\\n",
       "BELFER ROBERT                       44093.0               0.0   \n",
       "BHATNAGAR SANJAY                 15456290.0        -2604490.0   \n",
       "\n",
       "                  exercised_stock_options  total_stock_value  \n",
       "BELFER ROBERT                      3285.0           -44093.0  \n",
       "BHATNAGAR SANJAY                2604490.0                0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[stock[:-1]].sum(axis=1) != data.total_stock_value][stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = ['restricted_stock_deferred','restricted_stock', 'exercised_stock_options', 'total_stock_value']\n",
    "data.loc['BELFER ROBERT',correct] = np.array([-44093, 44093, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = ['restricted_stock_deferred','restricted_stock', 'exercised_stock_options', 'total_stock_value']\n",
    "data.loc['BHATNAGAR SANJAY',correct] = np.array([-2604490, 2604490, 15456290, 15456290])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo anterior foi realizado de maneira semelhante para os dados de ações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = ['to_messages',\n",
    "         'from_poi_to_this_person',\n",
    "         'from_messages',\n",
    "         'from_this_person_to_poi',\n",
    "         'shared_receipt_with_poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 5 columns):\n",
      "to_messages                86 non-null float64\n",
      "from_poi_to_this_person    86 non-null float64\n",
      "from_messages              86 non-null float64\n",
      "from_this_person_to_poi    86 non-null float64\n",
      "shared_receipt_with_poi    86 non-null float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data[email].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2007.111111</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>668.763889</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1058.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2417.142857</td>\n",
       "      <td>97.785714</td>\n",
       "      <td>300.357143</td>\n",
       "      <td>66.714286</td>\n",
       "      <td>1783.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       to_messages  from_poi_to_this_person  from_messages  \\\n",
       "poi                                                          \n",
       "False  2007.111111                58.500000     668.763889   \n",
       "True   2417.142857                97.785714     300.357143   \n",
       "\n",
       "       from_this_person_to_poi  shared_receipt_with_poi  \n",
       "poi                                                      \n",
       "False                36.277778              1058.527778  \n",
       "True                 66.714286              1783.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[email+[label]].groupby(label).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer(np.nan)\n",
    "data.loc[data[label] == 1, email] = imp.fit_transform(data[email][data[label]==1])\n",
    "data.loc[data[label] == 0, email] = imp.fit_transform(data[email][data[label]==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os atributos de e-mail apresentavam menos de 60% de completude. Para eles, optou-se por preencher os intervalos com a média dos valores de cada classe. A função \"Imputer\" da biblioteca _sklearn_ foi escolhida para o desenvolvimento da tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = list(set(payments)-set(few_poi_values))\n",
    "stock    = list(set(stock)-set(few_poi_values))\n",
    "email    = list(set(email)-set(few_poi_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>bonus</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>False</td>\n",
       "      <td>201955.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>13868.0</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>4175000.0</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>1407.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>2902.000000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>1058.527778</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>58.5</td>\n",
       "      <td>668.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>False</td>\n",
       "      <td>477.0</td>\n",
       "      <td>864523.0</td>\n",
       "      <td>56301.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>916197.0</td>\n",
       "      <td>5243487.0</td>\n",
       "      <td>1757552.0</td>\n",
       "      <td>4046157.0</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>False</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>1058.527778</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>58.5</td>\n",
       "      <td>668.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>False</td>\n",
       "      <td>239671.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>129142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>63014.0</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1058.527778</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>58.5</td>\n",
       "      <td>668.763889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      poi    salary      other  expenses  long_term_incentive  \\\n",
       "ALLEN PHILLIP K     False  201955.0      152.0   13868.0             304805.0   \n",
       "BADUM JAMES P       False       0.0        0.0    3486.0                  0.0   \n",
       "BANNANTINE JAMES M  False     477.0   864523.0   56301.0                  0.0   \n",
       "BAXTER JOHN C       False  267102.0  2660303.0   11200.0            1586055.0   \n",
       "BAY FRANKLIN R      False  239671.0       69.0  129142.0                  0.0   \n",
       "\n",
       "                        bonus  total_payments  total_stock_value  \\\n",
       "ALLEN PHILLIP K     4175000.0       4484442.0          1729541.0   \n",
       "BADUM JAMES P             0.0        182466.0           257817.0   \n",
       "BANNANTINE JAMES M        0.0        916197.0          5243487.0   \n",
       "BAXTER JOHN C       1200000.0       5634343.0         10623258.0   \n",
       "BAY FRANKLIN R       400000.0        827696.0            63014.0   \n",
       "\n",
       "                    restricted_stock  exercised_stock_options  \\\n",
       "ALLEN PHILLIP K             126027.0                1729541.0   \n",
       "BADUM JAMES P                    0.0                 257817.0   \n",
       "BANNANTINE JAMES M         1757552.0                4046157.0   \n",
       "BAXTER JOHN C              3942714.0                6680544.0   \n",
       "BAY FRANKLIN R              145796.0                      0.0   \n",
       "\n",
       "                    shared_receipt_with_poi  from_this_person_to_poi  \\\n",
       "ALLEN PHILLIP K                 1407.000000                65.000000   \n",
       "BADUM JAMES P                   1058.527778                36.277778   \n",
       "BANNANTINE JAMES M               465.000000                 0.000000   \n",
       "BAXTER JOHN C                   1058.527778                36.277778   \n",
       "BAY FRANKLIN R                  1058.527778                36.277778   \n",
       "\n",
       "                    to_messages  from_poi_to_this_person  from_messages  \n",
       "ALLEN PHILLIP K     2902.000000                     47.0    2195.000000  \n",
       "BADUM JAMES P       2007.111111                     58.5     668.763889  \n",
       "BANNANTINE JAMES M   566.000000                     39.0      29.000000  \n",
       "BAXTER JOHN C       2007.111111                     58.5     668.763889  \n",
       "BAY FRANKLIN R      2007.111111                     58.5     668.763889  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[label]+payments+stock+email]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 15)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, foram removidos os atributos listados por possuírem poucos dados de POIs, e as colunas do _dataset_ foram reordenadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Outliers Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poi                          False\n",
       "salary                           0\n",
       "other                            0\n",
       "expenses                         0\n",
       "long_term_incentive              0\n",
       "bonus                            0\n",
       "total_payments                   0\n",
       "total_stock_value                0\n",
       "restricted_stock                 0\n",
       "exercised_stock_options          0\n",
       "shared_receipt_with_poi    1058.53\n",
       "from_this_person_to_poi    36.2778\n",
       "to_messages                2007.11\n",
       "from_poi_to_this_person       58.5\n",
       "from_messages              668.764\n",
       "Name: LOCKHART EUGENE E, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc['LOCKHART EUGENE E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('LOCKHART EUGENE E', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['TOTAL', 'THE TRAVEL AGENCY IN THE PARK'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 15)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Houve a preocupação de procurar e remover valores atípicos, como por exemplo o indivíduo \"LOCKHART EUGENE E\" que , excetuando o rótulo \"poi\", não possuia informação alguma. Além disso, durante o estudo do pdf disponibilizado, foram encontrados dois registros que não representavam pessoas, são eles: \"TOTAL\", \"THE TRAVEL AGENCY IN THE PARK\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KBestTable(sel, df, features):\n",
    "    names = df[features].columns.values[sel.get_support()]\n",
    "    scores = pd.Series(sel.scores_, names).sort_values(ascending=False)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_stock_value          22.510549\n",
       "exercised_stock_options    22.348975\n",
       "bonus                      20.792252\n",
       "salary                     18.289684\n",
       "shared_receipt_with_poi    10.409148\n",
       "long_term_incentive         9.922186\n",
       "total_payments              9.283874\n",
       "restricted_stock            8.825442\n",
       "from_poi_to_this_person     5.478692\n",
       "expenses                    5.418900\n",
       "other                       4.202436\n",
       "from_this_person_to_poi     2.445551\n",
       "from_messages               1.050952\n",
       "to_messages                 0.660154\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = payments+stock+email\n",
    "sel = SelectKBest(f_classif, k = 'all').fit(data[features], data[label])\n",
    "KBestTable(sel, data, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os atributos de pagamento, ações e email foram avaliados com o auxílio da função \"SelectKBest\" do pacote \"sklearn\". Como parâmetros foram escolhidos o pontuador \"f_classif\", baseado em análise de variância, e \"k\" igual a \"all\" para pontuar todos os campos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ratio_from_poi'] = data.from_this_person_to_poi/data.from_messages\n",
    "data['ratio_to_poi']   = data.from_poi_to_this_person/data.to_messages\n",
    "data['ratio_with_poi'] = data.shared_receipt_with_poi/data.to_messages\n",
    "new = ['ratio_with_poi', 'ratio_to_poi', 'ratio_from_poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devido a baixa pontuação das colunas de e-mail novos campos foram criados com base nos existente, visando obter uma maior pontuação. Levantou-se a hipótese de que numeros brutos de e-mails recebidos e enviados podem não ser tão relevantes para identificação de pessoas de interesse quanto a proporção de e-mails enviados e recebidos entre os mesmos, ou seja, quanto mais um indivíduo se comunica com um poi, maior seria a chance desse mesmo também ser um, já que atividades ilicitas podem requerer cooperação de outros, o que os tornariam cúmplices e consequentemente pessoas de interesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratio_from_poi             25.878195\n",
       "ratio_with_poi             15.693633\n",
       "shared_receipt_with_poi    10.409148\n",
       "from_poi_to_this_person     5.478692\n",
       "ratio_to_poi                2.592766\n",
       "from_this_person_to_poi     2.445551\n",
       "from_messages               1.050952\n",
       "to_messages                 0.660154\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = email+new\n",
    "sel = SelectKBest(f_classif, k = 'all').fit(data[features], data[label])\n",
    "KBestTable(sel, data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os novos atributos foram avaliados em conjunto com os de e-mail. Nota-se uma melhora na pontuação dos campos criados em relação ao seus insumos, devido a isso deu-se preferência à utilização de tais campos em relação aos atributos de e-mail originais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratio_from_poi             25.878195\n",
       "total_stock_value          22.510549\n",
       "exercised_stock_options    22.348975\n",
       "bonus                      20.792252\n",
       "salary                     18.289684\n",
       "ratio_with_poi             15.693633\n",
       "long_term_incentive         9.922186\n",
       "total_payments              9.283874\n",
       "restricted_stock            8.825442\n",
       "expenses                    5.418900\n",
       "other                       4.202436\n",
       "ratio_to_poi                2.592766\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = payments+stock+email\n",
    "sel = SelectKBest(f_classif, k = 'all').fit(data[features], data[label])\n",
    "KBestTable(sel, data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi',\n",
       " 'salary',\n",
       " 'other',\n",
       " 'expenses',\n",
       " 'long_term_incentive',\n",
       " 'bonus',\n",
       " 'total_payments',\n",
       " 'total_stock_value',\n",
       " 'restricted_stock',\n",
       " 'exercised_stock_options',\n",
       " 'ratio_with_poi',\n",
       " 'ratio_to_poi',\n",
       " 'ratio_from_poi']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list = [label]+features\n",
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram selecionados os atributos de pagamentos, ações e as colunas de e-mails criadas no lugar das originais, além do rótulo, que será necessário para etapa de aprendizagem de máquina. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = data.to_dict(orient='index')\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após as etapas de análise, tratamento e seleção de dados, o _dataset_ foi transformado novamente em dicionário contando novamente com a ajuda do pacote _pandas_. Foram utilizadas as funções \"featureFormat\" e \"targetFeatureSplit\" disponibilizadas pela Udacity no pacote \"feature_format\". Como resultado, o dataset foi divido em rótulos e atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes  import GaussianNB\n",
    "from sklearn.tree         import DecisionTreeClassifier\n",
    "from sklearn.ensemble     import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Três algoritmos de aprendizagem de máquina foram selecionados: Naive Bayes, Árvore de decisão e Florestas aleatórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=1000, random_state=42)\n",
    "scoring = 'f1_macro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, também foram definidos o algoritmo de validação cruzada e a métrica de avaliação para escolha dos melhores parâmetros de cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parameters Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SKB__k': ['all', 2, 4, 6, 8, 10]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb = {'SKB__k': ['all'] + list(range(2,len(features[0]),2))}\n",
    "\n",
    "params = {}\n",
    "params.update(skb)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para iniciar o processo de escolha dos melhores parâmetros, foi adotado a função \"SelectKBest\" com os valores possíveis: 2, 4, 6, 8, 10 ou todos os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Tunning: 17.459 segundos\n",
      "Best Params:  {'SKB__k': 6}\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "nb = {}\n",
    "nb.update(params)\n",
    "params2 = params.copy().update(nb)\n",
    "pipe = Pipeline(steps=[('SKB', SelectKBest()), ('clf', GaussianNB())])\n",
    "clf = GridSearchCV(pipe, param_grid = nb, cv=cv, scoring = scoring).fit(features, labels)\n",
    "nb = clf.best_estimator_\n",
    "\n",
    "print('Params Tunning:', round(time() - t0, 3), 'segundos')\n",
    "print('Best Params: ', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('SKB', SelectKBest(k=6, score_func=<function f_classif at 0x7ff21d33b2f0>)), ('clf', GaussianNB(priors=None))])\n",
      "\tAccuracy: 0.84353\tPrecision: 0.39401\tRecall: 0.32250\tF1: 0.35469\tF2: 0.33465\n",
      "\tTotal predictions: 15000\tTrue positives:  645\tFalse positives:  992\tFalse negatives: 1355\tTrue negatives: 12008\n",
      "\n",
      "Validation Time: 1.538 segundos\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "test_classifier(nb, my_dataset, features_list)\n",
    "print('Validation Time:', round(time() - t0, 3), 'segundos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador \"GaussianNB\" não necessitou de otimização de parâmetros. Ainda assim, foi afinado a quantidade de atributos na busca do melhor valor para a métrica f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Tunning: 362.644 segundos\n",
      "Best Params:  {'SKB__k': 'all', 'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__min_samples_leaf': 2, 'clf__random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "dt = {'clf__criterion'        : ['gini', 'entropy'],\n",
    "      'clf__max_depth'        : [2, 4, 6],\n",
    "      'clf__min_samples_leaf' : [2, 4, 6],\n",
    "      'clf__random_state'     : [42]}\n",
    "\n",
    "dt.update(params)\n",
    "\n",
    "pipe = Pipeline(steps=[('SKB', SelectKBest()), ('clf', DecisionTreeClassifier())])\n",
    "clf = GridSearchCV(pipe, param_grid = dt, cv=cv, scoring=scoring).fit(features, labels)\n",
    "dt = clf.best_estimator_\n",
    "\n",
    "print('Params Tunning:', round(time() - t0, 3), 'segundos')\n",
    "print('Best Params: ', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('SKB', SelectKBest(k='all', score_func=<function f_classif at 0x7ff21d33b2f0>)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.89907\tPrecision: 0.57482\tRecall: 0.93350\tF1: 0.71151\tF2: 0.82993\n",
      "\tTotal predictions: 15000\tTrue positives: 1867\tFalse positives: 1381\tFalse negatives:  133\tTrue negatives: 11619\n",
      "\n",
      "Validation Time: 1.444 segundos\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "test_classifier(dt, my_dataset, features_list)\n",
    "print ('Validation Time:', round(time() - t0, 3), 'segundos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a árvore de decisão, além da quantidade de atributos utilizados, também foram afinados os parâmetros \"criterion\", \"max_depth\" e \"min_samples_leaf\". Os melhores parâmetros foram selecionados pela função \"GridSearchCV\" e utilizados pela função de avaliação disponibilizada pela Udacity, \"test_classifier\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Tunning: 604.336 segundos\n",
      "Best Params:  {'SKB__k': 10, 'clf__criterion': 'entropy', 'clf__max_depth': 2, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2, 'clf__n_estimators': 50, 'clf__random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "rf = {'clf__n_estimators' : [10, 25, 50],\n",
    "      'clf__criterion': ['entropy'],\n",
    "      'clf__max_depth': [2],\n",
    "      'clf__min_samples_leaf': [2],\n",
    "      'clf__min_samples_split': [2],\n",
    "      'clf__random_state': [42]}\n",
    "\n",
    "rf.update(params)\n",
    "\n",
    "pipe = Pipeline(steps=[('SKB', SelectKBest()), ('clf', RandomForestClassifier())])\n",
    "clf = GridSearchCV(pipe, param_grid = rf, cv=cv, scoring=scoring).fit(features, labels)\n",
    "rf = clf.best_estimator_\n",
    "\n",
    "print('Params Tunning:', round(time() - t0, 3), 'segundos')\n",
    "print('Best Params: ', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('SKB', SelectKBest(k=10, score_func=<function f_classif at 0x7ff21d33b2f0>)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=No...stimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.87673\tPrecision: 0.67933\tRecall: 0.14300\tF1: 0.23627\tF2: 0.16981\n",
      "\tTotal predictions: 15000\tTrue positives:  286\tFalse positives:  135\tFalse negatives: 1714\tTrue negatives: 12865\n",
      "\n",
      "Validation Time: 51.513 segundos\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "test_classifier(rf, my_dataset, features_list)\n",
    "print ('Validation Time:', round(time() - t0, 3), 'segundos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um procedimento semelhante ao usado no afinamento de parâmetros da árvore de decisão também foi utilizado para a floresta aleatória."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.427</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.623</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Precision  Recall     F1\n",
       "DecisionTree      0.577   0.923  0.710\n",
       "GaussianNB        0.427   0.324  0.368\n",
       "RandomForest      0.623   0.146  0.237"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.DataFrame({'GaussianNB'   : [0.427, 0.324, 0.368],\n",
    "                    'DecisionTree' : [0.577, 0.923, 0.710],\n",
    "                    'RandomForest' : [0.623, 0.146, 0.237]},\n",
    "                    index=['Precision', 'Recall', 'F1'])\n",
    "\n",
    "val.T.sort_values(by='F1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_classifier_and_data(dt, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mostra a tabela acima, em relação à métrica F1, a árvore de decisão foi o algoritmo que se saiu melhor dentre os três estudados. O algoritmo tal como o _dataset_ e a lista de atributos foram serializados e salvos em disco com o auxílio da função \"dump_classifier_and_data\" disponibilizada pela Udacity por meio do pacote \"teste.py\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  [relevant rubric items: “data exploration”, “outlier investigation”]\n",
    "\n",
    "R: O objetivo do projeto é identificar possíveis pessoas de interesses (POIs) da empresa Enron, ou seja, funcionários que possam ter participado da fraude que levou uma das maiores empresas dos EUA à falência. Para isso, um modelo preditivo pode ser construído a fim de auxiliar na identificação, modelado a partir de dados de indivíduos que já foram considerados POI, onde possíveis padrões possam encontrados e utilizados para detecção de outros.\n",
    "Como insumo foram disponibilizados dados públicos com 14 atributos financeiros, 6 relacionados a e-mails e 1 rótulo pré-processados, referentes à 146 indivíduos. Infelizmente, haviam algumas informações faltando e pouca quantidade de pessoas de interesse (apenas 18).\n",
    "Além disso, alguns registros foram removidos por serem considerados _outliers_, como por exemplo a linha \"LOCKHART EUGENE E\" que possuia apenas valores faltantes, e as linhas \"TOTAL\" e \"THE TRAVEL AGENCY IN THE PARK\" que não representavam pessoas.\n",
    "\n",
    "\n",
    "> 1. What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]\n",
    "\n",
    "R: Todas as 21 colunas do _dataset_ foram avalidas utilizando uma métrica baseada em Análise de Variância (f_classif) em conjunto com uma função de seleção dos melhores parâmetros (SelectKBest), de acordo com tal métrica.\n",
    "Devido a baixa relevância dos atributos de e-mail nesta avaliação, foram criados novos atributos utilizando aqueles como insumo, levando em consideração a hipótese de que a proporção de e-mails enviadas, recebidas e compartilhadas com pessoas de interesse possa ser mais relevante que a quantidade bruta desses valores. Os novos campos obtiveram pontuações melhores na avaliação, e portanto, foram usados em vez dos antigos.\n",
    "Não foi necessário realizar dimensionamento dos dados, já que os algoritmos selecionados não demandavam tal processamento. A escolha de características para cada modelo foi feita automaticamente utilizando função para aprimoramento sistemático de parâmetros (GridSearchCV).\n",
    "\n",
    "\n",
    "> 1. What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]\n",
    "\n",
    "R: Foram escolhidos três algoritmos para geração dos modelos: Naive Bayes Gaussiano, Árvore de Decisão e Floresta Aleatória. Os algoritmos passaram por um processo de otimização de parâmetros, a fim de obter a melhor combinação deles que maximizasse o valor da métrica F1. Para isso o GridSearchCV foi utilizado para selecioanar o melhor número de caracteriscas e os melhores parâmetros de cada algoritmo (dentre os disponibilizados). O algoritmo de melhor desempenho foi a Árvore de Decisão, obtendo o valor 0.710 para a métrica F1, 0.923 para a métrica abrangência e 0.577 para a métrica precisão. O resultado foi satisfatório já que as duas últimas métricas apresentaram valores maiores que 0.3, atendendo assim aos requisitos do projeto.\n",
    "\n",
    "\n",
    "> 1. What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).  [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]\n",
    "\n",
    "R: Afinar os parâmetros de um algoritmo significa escolher os melhores valores para maximizar a pontuação de acordo com uma métrica definida, ou seja, escolher os melhores valores para obter o melhor modelo para aquele cenário. O processo foi feito sistemáticamente utilizando o GridSearchCV e listando possíveis valores para parâmetros selecionados, e repetido para os três algoritmos escolhidos. Além de selecionar a melhor quantidade de características a ser utilizada por cada modelo com ajuda de _pipeline_ utilizando função de mesmo nome presente no pacote _sklearn_. Algum dos parâmetros ajustados, não citados acima, foram: numero de árvores da floresta aleatória, critério de seleção, profundidade máxima e quantidade mínima de folhas da árvore de decisão.\n",
    "\n",
    "\n",
    "\n",
    "> 1. What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric items: “discuss validation”, “validation strategy”]\n",
    "\n",
    "R: A validação pode ser utilizada para avaliar o nível de aprendizado de um modelo.É possível ensinar e treinar o modelo com a totalidade dos dados, o que pode acabar apresentando grande variância, fazendo com que o modelo apresente bons resultados para os dados de treinamento, mas que apresentem uma performance muito inferior para dados novos por não conseguir generalizar o aprendizado. Deste modo, a fim de minimizar o erro de generalização, foi utilizada validação cruzada com a função \"StratifiedShuffleSplit\" da biblioteca _sklearn_, por meio dessa foi possível misturar e separar os dados em conjuntos de treinamento e teste várias vezes.\n",
    "\n",
    "> 1. Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]\n",
    "\n",
    "R: Foram levadas em consideração três métricas para avaliação do modelo: precisão (precision), abrangência (recall) e F1 (F1). Precisão refere-se à quantidade de pessoas identificadas como POI pelo modelo, que eram realmente pessoas de interesses. Quanto à abrangência, entende-se que de todos os POIs existentes no conjunto de dados, quantos foram identificados. Já a métrica F1 representa uma média harmônica entre as duas outras métricas citadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. <https://github.com/MwillianM/FlchainExploration>\n",
    "1. <https://github.com/MwillianM/OpenStreetMapDataWrangling>\n",
    "1. <https://github.com/udacity/ud120-projects>\n",
    "1. <https://br.udacity.com/>\n",
    "1. <https://stackoverflow.com/>\n",
    "1. <https://pandas.pydata.org/>\n",
    "1. <http://www.numpy.org/>\n",
    "1. <http://scikit-learn.org/>\n",
    "1. <https://stats.stackexchange.com/>\n",
    "1. <https://olegleyz.github.io/enron_classifier.html>\n",
    "1. <https://medium.com/@williamkoehrsen/machine-learning-with-python-on-the-enron-dataset-8d71015be26d/>\n",
    "1. <https://www.kaggle.com/tsilveira/machine-learning-tutorial-enron-e-mails>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
